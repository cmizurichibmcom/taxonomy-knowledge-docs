- Main page

- Contents

- Current events

- Random article

- About Wikipedia

- Contact us

- Help

- Learn to edit

- Community portal

- Recent changes

- Upload file

<!-- image -->

<!-- image -->

<!-- image -->

- Donate

- Create account

- Log in

- Create account

- Log in

- Contributions

- Talk

## Contents

- (Top)

- 

# IBM Granite

- Article

- Talk

- Read

- Edit

- View history

- Read

- Edit

- View history

- What links here

- Related changes

- Upload file

- Special pages

- Permanent link

- Page information

- Cite this page

- Get shortened URL

- Download QR code

- Wikidata item

- Download as PDF

- Printable version

|                 |                                              |
|-----------------|----------------------------------------------|
| Developer(s)    | IBM Research[1]                              |
| Initial release | November 7, 2023; 11 months ago (2023-11-07) |
| Platform        | IBM Watsonx (initially)
GitHub
Hugging Face
RHEL AI                                              |
| Type            | Multimodal
Large language model
Generative pre-trained transformer
Foundation model                                              |
| License         | Proprietary
Code models: Open Source (Apache 2.0)[2]                                              |

| Part of a series on   |
|-----------------------|
| Machine learning
and data mining                       |
| Paradigms
Supervised learning
Unsupervised learning
Semi-supervised learning
Self-supervised learning
Reinforcement learning
Meta-learning
Online learning
Batch learning
Curriculum learning
Rule-based learning
Neuro-symbolic AI
Neuromorphic engineering
Quantum machine learning                       |
| Problems
Classification
Generative modeling
Regression
Clustering
Dimensionality reduction
Density estimation
Anomaly detection
Data cleaning
AutoML
Association rules
Semantic analysis
Structured prediction
Feature engineering
Feature learning
Learning to rank
Grammar induction
Ontology learning
Multimodal learning                       |
| Supervised learning
(classification • regression) 
Apprenticeship learning
Decision trees
Ensembles
Bagging
Boosting
Random forest
k-NN
Linear regression
Naive Bayes
Artificial neural networks
Logistic regression
Perceptron
Relevance vector machine (RVM)
Support vector machine (SVM)                       |
| Clustering
BIRCH
CURE
Hierarchical
k-means
Fuzzy
Expectation–maximization (EM)

DBSCAN
OPTICS
Mean shift                       |
| Dimensionality reduction
Factor analysis
CCA
ICA
LDA
NMF
PCA
PGD
t-SNE
SDL                       |
| Structured prediction
Graphical models
Bayes net
Conditional random field
Hidden Markov                       |
| Anomaly detection
RANSAC
k-NN
Local outlier factor
Isolation forest                       |
| Artificial neural network
Autoencoder
Deep learning
Feedforward neural network
Recurrent neural network
LSTM
GRU
ESN
reservoir computing
Boltzmann machine
Restricted
GAN
Diffusion model
SOM
Convolutional neural network
U-Net
LeNet
AlexNet
DeepDream
Neural radiance field
Transformer
Vision
Mamba
Spiking neural network
Memtransistor
Electrochemical RAM (ECRAM)                       |
| Reinforcement learning
Q-learning
SARSA
Temporal difference (TD)
Multi-agent
Self-play                       |
| Learning with humans
Active learning
Crowdsourcing
Human-in-the-loop
RLHF                       |
| Model diagnostics
Coefficient of determination
Confusion matrix
Learning curve
ROC curve                       |
| Mathematical foundations
Kernel machines
Bias–variance tradeoff
Computational learning theory
Empirical risk minimization
Occam learning
PAC learning
Statistical learning
VC theory                       |
| Journals and conferences
ECML PKDD
NeurIPS
ICML
ICLR
IJCAI
ML
JMLR                       |
| Related articles
Glossary of artificial intelligence
List of datasets for machine-learning research
List of datasets in computer vision and image processing
Outline of machine learning                       |
| vte                   |

IBM Granite is a series of decoder-only AI foundation models created by IBM. It was announced on September 7, 2023,[3][4] and an initial paper was published 4 days later.[5] Initially intended for use in the IBM's cloud-based data and generative AI platform Watsonx along with other models,[6] IBM opened the source code of some code models.[7] Granite models are trained on datasets curated from Internet, academic publishings, code datasets, legal and finance documents.[8][9][1]

## Foundation models

A foundation model is an AI model trained on broad data at scale such that it can be adapted to a wide range of downstream tasks.[10]

Granite's first foundation models were Granite.13b.instruct and Granite.13b.chat. The "13b" in their name comes from 13 billion, the amount of parameters they have as models, lesser than most of the larger models of the time.  Later models vary from 3 to 34 billion parameters.[3][11]

On May 6, 2024, IBM released the source code of four variations of Granite Code Models under Apache 2, an open source permissive license that allows completely free use, modification and sharing of the software, and put them on Hugging Face for public use.[12][13] According to IBM's own report, Granite 8b outperforms Llama 3 on several coding related tasks within similar range of parameters.[14][15]

## See also

- Mistral AI, a company that also provides open source models

- GPT

- LLaMA

- Cyc

- Gemini

## References

1. ^ a b McDowell, Steve. "IBM's New Granite Foundation Models Enable Safe Enterprise AI". Forbes.

2. ^ ibm-granite/granite-code-models, IBM Granite, 2024-05-08, retrieved 2024-05-08

3. ^ a b Nirmal, Dinesh (September 7, 2023). "Building AI for business: IBM's Granite foundation models". IBM.

4. ^ "IBM debuts Granite series of hardware-efficient language models". September 7, 2023.

5. ^ "Granite Foundation Models" (PDF). IBM. 2023-11-30.

6. ^ Fritts, Harold (2024-04-22). "IBM Adds Meta Llama 3 To watsonx, Expands AI Offerings". StorageReview.com. Retrieved 2024-05-08.

7. ^ Jindal, Siddharth (2024-05-07). "IBM Releases Open-Source Granite Code Models, Outperforms Llama 3". Analytics India Magazine. Retrieved 2024-05-08.

8. ^ Azhar, Ali (2024-04-08). "IBM Patents a Faster Method to Train LLMs for Enterprises". Datanami. Retrieved 2024-05-08.

9. ^ Wiggers, Kyle (2023-09-07). "IBM rolls out new generative AI features and models". TechCrunch. Retrieved 2024-05-08.

10. ^ "Introducing the Center for Research on Foundation Models (CRFM)". Stanford HAI. 18 August 2021.

11. ^ Pawar, Sahil (2023-09-11). "IBM Introduces Granite Series LLM Models for Watsonx Platform". Analytics Drift. Retrieved 2024-05-09.

12. ^ Nine, Adrianna (May 7, 2024). "IBM Makes Granite AI Models Open-Source Under New InstructLab Platform". ExtremeTech.

13. ^ "IBM open-sources its Granite AI models - and they mean business". ZDNET. Retrieved 2024-05-21.

14. ^ Jindal, Siddharth (2024-05-07). "IBM Releases Open-Source Granite Code Models, Outperforms Llama 3". Analytics India Magazine. Retrieved 2024-05-09.

15. ^ Synced (2024-05-13). "IBM's Granite Code: Powering Enterprise Software Development with AI Precision | Synced". syncedreview.com. Retrieved 2024-05-21.

## External links

- GitHub page

<!-- image -->

- IBM products

- IBM software

- Large language models

- Generative artificial intelligence

- Artificial neural networks

- 2023 software

- Free software

- Articles with short description

- Short description matches Wikidata

- This page was last edited on 21 September 2024, at 10:34 (UTC).

- Text is available under the Creative Commons Attribution-ShareAlike 4.0 License;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.

- Privacy policy

- About Wikipedia

- Disclaimers

- Contact Wikipedia

- Code of Conduct

- Developers

- Statistics

- Cookie statement

- Mobile view

- 